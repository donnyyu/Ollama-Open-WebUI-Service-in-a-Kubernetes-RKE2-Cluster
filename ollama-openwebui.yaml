---
# Persistent Volume
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ollama-models-pv
  labels:
    app: ollama
spec:
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /opt/ollama-data
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: nvidia.com/gpu.present
          operator: In
          values:
          - "true"
        - key: nvidia.com/gpu.product
          operator: In
          values:
          - "NVIDIA-GeForce-RTX-3060"

---
# Persistent Volume Claim
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ollama-models-pvc
  namespace: ollama
  labels:
    app: ollama
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: local-storage
  volumeName: ollama-models-pv

---
# Service
apiVersion: v1
kind: Service
metadata:
  name: ollama-service
  namespace: ollama
  labels:
    app: ollama
spec:
  selector:
    app: ollama
  ports:
    - name: http
      port: 11434
      targetPort: 11434
      protocol: TCP
  type: ClusterIP

---
# Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-deployment
  namespace: ollama
  labels:
    app: ollama
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      nodeSelector:
        nvidia.com/gpu.present: "true"
        nvidia.com/gpu.product: "NVIDIA-GeForce-RTX-3060"

      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.present
                operator: In
                values:
                - "true"
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - "NVIDIA-GeForce-RTX-3060"
      containers:
      - name: ollama
        image: ollama/ollama:latest
        ports:
        - containerPort: 11434
          name: http
        env:
        - name: OLLAMA_HOST
          value: "0.0.0.0"
        - name: OLLAMA_ORIGINS
          value: "*"
        - name: OLLAMA_MODELS
          value: "/root/.ollama/models"
        volumeMounts:
        - name: ollama-models
          mountPath: /root/.ollama/models
        - name: ollama-config
          mountPath: /root/.ollama
        resources:
      volumes:
      - name: ollama-models
        persistentVolumeClaim:
          claimName: ollama-models-pvc
      - name: ollama-config
        emptyDir: {}
      restartPolicy: Always
      runtimeClassName: nvidia
      # Security context
      securityContext:
        runAsNonRoot: false
        runAsUser: 0
        fsGroup: 0

---
# Optional: Ingress for external access
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ollama-ingress
  namespace: default
  labels:
    app: ollama
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
spec:
  ingressClassName: nginx
  rules:
  - host: ollama.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: ollama-service
            port:
              number: 11434

---
# Open WebUI PV
apiVersion: v1
kind: PersistentVolume
metadata:
  name: open-webui-pv
  labels:
    app: open-webui
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /opt/open-webui-data
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: nvidia.com/gpu.present
          operator: In
          values:
          - "true"
        - key: nvidia.com/gpu.product
          operator: In
          values:
          - "NVIDIA-GeForce-RTX-3060"

---
# Open WebUI PVC
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: open-webui-pvc
  namespace: ollama
  labels:
    app: open-webui
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: local-storage
  volumeName: open-webui-pv

---
# Open WebUI Service
apiVersion: v1
kind: Service
metadata:
  name: open-webui-service
  namespace: ollama
  labels:
    app: open-webui
spec:
  type: NodePort
  selector:
    app: open-webui
  ports:
    - name: http
      protocol: TCP
      port: 8080
      targetPort: 8080
      nodePort: 30088


---
# Open WebUI Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: open-webui-deployment
  namespace: ollama
  labels:
    app: open-webui
spec:
  replicas: 1
  selector:
    matchLabels:
      app: open-webui
  template:
    metadata:
      labels:
        app: open-webui
    spec:
      containers:
      - name: open-webui
        image: ghcr.io/open-webui/open-webui:main
        ports:
        - containerPort: 8080
          name: http
        volumeMounts:
        - name: webui-data
          mountPath: /app/backend/data
        env:
        - name: OLLAMA_BASE_URL
          value: "http://ollama-service:11434"

      volumes:
      - name: webui-data
        persistentVolumeClaim:
          claimName: open-webui-pvc
      restartPolicy: Always
---
# Open WebUI Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: open-webui-ingress
  namespace: ollama
  labels:
    app: open-webui
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
spec:
  ingressClassName: nginx
  rules:
  - host: open-webui.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: open-webui-service
            port:
              number: 8080